{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello,TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "hello=tf.constant(\"Hello,TensorFlow!\")\n",
    "sess=tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 常量、变量和占位符"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**常量(constant)** 同其他语言的常量, 在赋值后不可修改。`tf.constant( value, dtype=None, shape=None, name='Const', verify_shape=False )`\n",
    "\n",
    "**占位符(placeholder)** 同其他语言的方法的参数, 在执行方法时设置。`tf.placeholder( dtype, shape=None, name=None )` \n",
    "\n",
    "**变量(Variable)** 比较特殊, 机器学习特有属性. 对于常规的算法而言, 在输入值已知的情况下, 优化变量(参数)使损失函数的值达到最小. 因而在含有优化器(Optimizer)的算法中, 变量是动态计算(变化)的. 如果在未使用优化器时, 变量仍作为普通变量. 注意: 在使用变量之前, 需要执行初始化方法, 系统才会为其赋值。`tf.Variable('initial-value', name='optional-name')`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通过feed设置placeholder的值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有的时候，我们会在声明变量的时候不赋值，计算的时候才进行赋值，这个时候feed就派上用场了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.0\n"
     ]
    }
   ],
   "source": [
    "# 创建变量占位符input1和input2\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "\n",
    "# 加法操作，把input1和input2相加\n",
    "new_val = tf.add(input1,input2)\n",
    "\n",
    "# 使用这种写法运行会话，在运行完毕后，会话自动关闭\n",
    "with tf.Session() as sess:\n",
    "    # 打印new_val值，运算时用feed_dict设置两个输入的值\n",
    "    print(sess.run(new_val,feed_dict={input1:10.0,input2:7.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用TensorFlow训练线性回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  50 loss:5.01547\n",
      "epoch:  100 loss:4.28971\n",
      "epoch:  150 loss:3.74645\n",
      "epoch:  200 loss:3.33981\n",
      "epoch:  250 loss:3.03543\n",
      "epoch:  300 loss:2.80759\n",
      "epoch:  350 loss:2.63704\n",
      "epoch:  400 loss:2.50939\n",
      "epoch:  450 loss:2.41384\n",
      "epoch:  500 loss:2.34231\n",
      "epoch:  550 loss:2.28877\n",
      "epoch:  600 loss:2.24870\n",
      "epoch:  650 loss:2.21870\n",
      "epoch:  700 loss:2.19625\n",
      "epoch:  750 loss:2.17944\n",
      "epoch:  800 loss:2.16686\n",
      "epoch:  850 loss:2.15744\n",
      "epoch:  900 loss:2.15039\n",
      "epoch:  950 loss:2.14512\n",
      "epoch:  1000 loss:2.14117\n",
      "W: [2.9981267] b: [1.9818181] loss: 2.1411703\n"
     ]
    }
   ],
   "source": [
    "# 创建变量w和b节点，并设置初始值\n",
    "w = tf.Variable([.1], dtype=tf.float32)\n",
    "b = tf.Variable([-.1], dtype=tf.float32)\n",
    "\n",
    "# x节点，用于输入数据\n",
    "x = tf.placeholder(tf.float32)\n",
    "\n",
    "# 创建线性模型\n",
    "linear_model = w*x + b\n",
    "\n",
    "# 创建 y 节点，用来输入训练数据的y，用于损失模型计算\n",
    "y = tf.placeholder(tf.float32)\n",
    "\n",
    "# 创建损失模型\n",
    "loss = tf.reduce_sum(tf.square(linear_model - y))\n",
    "sess = tf.Session()\n",
    "\n",
    "# 初始化变量 变量需要经过下面的 init 过程后才能使用\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# 创建一个梯度下降优化器，学习率0.001\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.001)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "display_step = 50\n",
    "\n",
    "# 训练数据\n",
    "x_train = [1,2,3,6,8]\n",
    "y_train = [4.8, 8.5, 10.4, 21.0, 25.3]\n",
    "\n",
    "# 训练1000次\n",
    "for i in range(1000):\n",
    "    sess.run(train, {x: x_train, y: y_train})\n",
    "    \n",
    "    if (i + 1) % display_step == 0:\n",
    "        print('epoch: ',i+1 ,'loss:{:.5f}'.format(sess.run(loss,{x: x_train, y: y_train})))\n",
    "\n",
    "# 打印训练后的结果\n",
    "print('W: %s b: %s loss: %s' % (sess.run(w), sess.run(\n",
    "    b), sess.run(loss, {x: x_train, y: y_train})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试\n",
    "test_pred = np.array([[1,0,0],[0,0,1],[0,1,0],[1,0,0]])\n",
    "y_test = np.array([[0,0,0],[0,0,1],[0,0,1],[1,0,0]])\n",
    "a = tf.equal(tf.argmax(test_pred, 1), tf.argmax(y_test, 1))\n",
    "c = tf.cast(a, tf.float32)\n",
    "tf.Session().run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Session().run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
